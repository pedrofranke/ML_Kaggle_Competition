{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15674932</td>\n",
       "      <td>Okwudilichukwu</td>\n",
       "      <td>668</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15749177</td>\n",
       "      <td>Okwudiliolisa</td>\n",
       "      <td>627</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15694510</td>\n",
       "      <td>Hsueh</td>\n",
       "      <td>678</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15741417</td>\n",
       "      <td>Kao</td>\n",
       "      <td>581</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15766172</td>\n",
       "      <td>Chiemenam</td>\n",
       "      <td>716</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  CustomerId         Surname  CreditScore Geography Gender   Age  Tenure  \\\n",
       "0   0    15674932  Okwudilichukwu          668    France   Male  33.0       3   \n",
       "1   1    15749177   Okwudiliolisa          627    France   Male  33.0       1   \n",
       "2   2    15694510           Hsueh          678    France   Male  40.0      10   \n",
       "3   3    15741417             Kao          581    France   Male  34.0       2   \n",
       "4   4    15766172       Chiemenam          716     Spain   Male  33.0       5   \n",
       "\n",
       "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0       0.00              2        1.0             0.0        181449.97   \n",
       "1       0.00              2        1.0             1.0         49503.50   \n",
       "2       0.00              2        1.0             0.0        184866.69   \n",
       "3  148882.54              1        1.0             1.0         84560.88   \n",
       "4       0.00              2        1.0             1.0         15068.83   \n",
       "\n",
       "   Exited  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('Datasets/train.csv') # using pandas to read the test set\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>668</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>627</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>678</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>716</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography Gender   Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          668    France   Male  33.0       3       0.00              2   \n",
       "1          627    France   Male  33.0       1       0.00              2   \n",
       "2          678    France   Male  40.0      10       0.00              2   \n",
       "3          581    France   Male  34.0       2  148882.54              1   \n",
       "4          716     Spain   Male  33.0       5       0.00              2   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0        1.0             0.0        181449.97       0  \n",
       "1        1.0             1.0         49503.50       0  \n",
       "2        1.0             0.0        184866.69       0  \n",
       "3        1.0             1.0         84560.88       0  \n",
       "4        1.0             1.0         15068.83       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useless_cols = ['id','CustomerId','Surname']\n",
    "df_train.drop(columns=useless_cols,inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>668</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>627</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>678</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>716</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165029</th>\n",
       "      <td>667</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131834.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165030</th>\n",
       "      <td>792</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131834.45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165031</th>\n",
       "      <td>565</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127429.56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165032</th>\n",
       "      <td>554</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7</td>\n",
       "      <td>161533.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71173.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165033</th>\n",
       "      <td>850</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61581.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165034 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore   Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0               668  33.0       3       0.00              2        1.0   \n",
       "1               627  33.0       1       0.00              2        1.0   \n",
       "2               678  40.0      10       0.00              2        1.0   \n",
       "3               581  34.0       2  148882.54              1        1.0   \n",
       "4               716  33.0       5       0.00              2        1.0   \n",
       "...             ...   ...     ...        ...            ...        ...   \n",
       "165029          667  33.0       2       0.00              1        1.0   \n",
       "165030          792  35.0       3       0.00              1        0.0   \n",
       "165031          565  31.0       5       0.00              1        1.0   \n",
       "165032          554  30.0       7  161533.00              1        0.0   \n",
       "165033          850  31.0       1       0.00              1        1.0   \n",
       "\n",
       "        IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0                  0.0        181449.97       0                 1   \n",
       "1                  1.0         49503.50       0                 1   \n",
       "2                  0.0        184866.69       0                 1   \n",
       "3                  1.0         84560.88       0                 1   \n",
       "4                  1.0         15068.83       0                 0   \n",
       "...                ...              ...     ...               ...   \n",
       "165029             1.0        131834.75       0                 0   \n",
       "165030             0.0        131834.45       0                 1   \n",
       "165031             1.0        127429.56       0                 1   \n",
       "165032             1.0         71173.03       0                 0   \n",
       "165033             0.0         61581.79       1                 1   \n",
       "\n",
       "        Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                       0                0              0            1  \n",
       "1                       0                0              0            1  \n",
       "2                       0                0              0            1  \n",
       "3                       0                0              0            1  \n",
       "4                       0                1              0            1  \n",
       "...                   ...              ...            ...          ...  \n",
       "165029                  0                1              1            0  \n",
       "165030                  0                0              0            1  \n",
       "165031                  0                0              0            1  \n",
       "165032                  0                1              1            0  \n",
       "165033                  0                0              0            1  \n",
       "\n",
       "[165034 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_cols = ['Geography','Gender']\n",
    "target = ['Exited']\n",
    "\n",
    "df_train = pd.get_dummies(df_train,columns=string_cols,dtype=int)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>668</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>627</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>678</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>716</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore   Age  Tenure  Balance  NumOfProducts  HasCrCard  \\\n",
       "0          668  33.0       3        0              2        1.0   \n",
       "1          627  33.0       1        0              2        1.0   \n",
       "2          678  40.0      10        0              2        1.0   \n",
       "3          581  34.0       2        1              1        1.0   \n",
       "4          716  33.0       5        0              2        1.0   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0             0.0        181449.97       0                 1   \n",
       "1             1.0         49503.50       0                 1   \n",
       "2             0.0        184866.69       0                 1   \n",
       "3             1.0         84560.88       0                 1   \n",
       "4             1.0         15068.83       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                  0                0              0            1  \n",
       "1                  0                0              0            1  \n",
       "2                  0                0              0            1  \n",
       "3                  0                0              0            1  \n",
       "4                  0                1              0            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Balance'] = df_train.Balance.apply(lambda x: 0 if x == 0 else 1)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = df_train[df_train.HasCrCard == 1]\n",
    "df_train2 = df_train[df_train.HasCrCard == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124428, 14)\n"
     ]
    }
   ],
   "source": [
    "print(df_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40606, 14)\n"
     ]
    }
   ],
   "source": [
    "print(df_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df_train1.drop(columns=['Exited','HasCrCard'])\n",
    "y1 = df_train1.Exited\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1,y1,test_size=0.2,stratify=y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df_train2.drop(columns=['Exited','HasCrCard'])\n",
    "y2 = df_train2.Exited\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2,test_size=0.2,stratify=y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>602</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135082.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>559</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180890.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>773</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87549.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>616</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59346.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>797</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62402.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165019</th>\n",
       "      <td>719</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77500.48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165021</th>\n",
       "      <td>632</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128528.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165022</th>\n",
       "      <td>577</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148811.14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165030</th>\n",
       "      <td>792</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131834.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165032</th>\n",
       "      <td>554</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71173.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40606 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore   Age  Tenure  Balance  NumOfProducts  IsActiveMember  \\\n",
       "16              602  36.0       7        0              2             1.0   \n",
       "19              559  61.0       1        1              1             1.0   \n",
       "20              773  35.0       9        0              2             1.0   \n",
       "26              616  31.0       3        1              2             1.0   \n",
       "32              797  55.0       0        1              2             1.0   \n",
       "...             ...   ...     ...      ...            ...             ...   \n",
       "165019          719  32.0       6        1              1             1.0   \n",
       "165021          632  41.0       6        0              2             1.0   \n",
       "165022          577  45.0       2        0              1             0.0   \n",
       "165030          792  35.0       3        0              1             0.0   \n",
       "165032          554  30.0       7        1              1             1.0   \n",
       "\n",
       "        EstimatedSalary  Geography_France  Geography_Germany  Geography_Spain  \\\n",
       "16            135082.47                 1                  0                0   \n",
       "19            180890.40                 1                  0                0   \n",
       "20             87549.36                 0                  0                1   \n",
       "26             59346.40                 0                  0                1   \n",
       "32             62402.38                 0                  0                1   \n",
       "...                 ...               ...                ...              ...   \n",
       "165019         77500.48                 1                  0                0   \n",
       "165021        128528.83                 0                  0                1   \n",
       "165022        148811.14                 1                  0                0   \n",
       "165030        131834.45                 1                  0                0   \n",
       "165032         71173.03                 0                  0                1   \n",
       "\n",
       "        Gender_Female  Gender_Male  \n",
       "16                  0            1  \n",
       "19                  0            1  \n",
       "20                  0            1  \n",
       "26                  0            1  \n",
       "32                  1            0  \n",
       "...               ...          ...  \n",
       "165019              1            0  \n",
       "165021              1            0  \n",
       "165022              1            0  \n",
       "165030              0            1  \n",
       "165032              1            0  \n",
       "\n",
       "[40606 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado el analisis de XGBoost\n",
      "\n",
      "{'Model': 'XGBoost', 'Best_Params': {'booster': 'gbtree', 'eta': 0.05, 'max_depth': 5, 'n_estimators': 70}, 'Test_Accuracy': 0.870087599453508}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Params</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'booster': 'gbtree', 'eta': 0.05, 'max_depth'...</td>\n",
       "      <td>0.870088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model                                        Best_Params  Test_Accuracy\n",
       "0  XGBoost  {'booster': 'gbtree', 'eta': 0.05, 'max_depth'...       0.870088"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    #'LightGBM': LGBMClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    #'RandomForest': RandomForestClassifier(),\n",
    "    #'GradientBoosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    #'LightGBM':{'n_estimators': [10,30,50, 100, 200],'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "    'XGBoost': {'n_estimators': [ 30,50,70], 'max_depth': [5, 7,10],'booster':['gbtree'],'eta':[0.1,0.05]},\n",
    "    #'RandomForest': {'n_estimators': [50], 'max_depth': [None, 10]},\n",
    "    #'GradientBoosting': {'n_estimators': [50], 'max_depth': [3, 7]}\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train1, y_train1)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    y_pred = grid_search.predict(X_test1)\n",
    "    accuracy = accuracy_score(y_test1, y_pred)\n",
    "\n",
    "    result = {\n",
    "        'Model': model_name,\n",
    "        'Best_Params': best_params,\n",
    "        'Test_Accuracy': accuracy\n",
    "    }\n",
    "    results.append(result)\n",
    "    print(f'Finalizado el analisis de {model_name}\\n')\n",
    "    print(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado el analisis de XGBoost\n",
      "\n",
      "{'Model': 'XGBoost', 'Best_Params': {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 5, 'n_estimators': 50}, 'Test_Accuracy': 0.8468357547402118}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Params</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'booster': 'gbtree', 'eta': 0.1, 'max_depth':...</td>\n",
       "      <td>0.846836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model                                        Best_Params  Test_Accuracy\n",
       "0  XGBoost  {'booster': 'gbtree', 'eta': 0.1, 'max_depth':...       0.846836"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    #'LightGBM': LGBMClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    #'RandomForest': RandomForestClassifier(),\n",
    "    #'GradientBoosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    #'LightGBM':{'n_estimators': [10,30,50, 100, 200],'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "    'XGBoost': {'n_estimators': [ 30,50,70], 'max_depth': [5, 7,10],'booster':['gbtree'],'eta':[0.1,0.05]},\n",
    "    #'RandomForest': {'n_estimators': [50], 'max_depth': [None, 10]},\n",
    "    #'GradientBoosting': {'n_estimators': [50], 'max_depth': [3, 7]}\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train2, y_train2)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    y_pred = grid_search.predict(X_test2)\n",
    "    accuracy = accuracy_score(y_test2, y_pred)\n",
    "\n",
    "    result = {\n",
    "        'Model': model_name,\n",
    "        'Best_Params': best_params,\n",
    "        'Test_Accuracy': accuracy\n",
    "    }\n",
    "    results.append(result)\n",
    "    print(f'Finalizado el analisis de {model_name}\\n')\n",
    "    print(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exited</th>\n",
       "      <th>pred_result</th>\n",
       "      <th>Ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22639</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115409</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88551</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117530</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158218</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102916</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92555</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134417</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8122 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Exited  pred_result     Ok\n",
       "22639        0            0   True\n",
       "115409       1            1   True\n",
       "4650         1            0  False\n",
       "88551        0            0   True\n",
       "117530       0            0   True\n",
       "...        ...          ...    ...\n",
       "158218       0            0   True\n",
       "102916       0            1  False\n",
       "100603       0            0   True\n",
       "92555        0            0   True\n",
       "134417       0            0   True\n",
       "\n",
       "[8122 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test2 = pd.DataFrame(y_test2)\n",
    "\n",
    "y_test2['pred_result'] = y_pred\n",
    "\n",
    "y_test2['Ok'] = (y_test2['Exited'] == y_test2['pred_result'])\n",
    "y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2_final = pd.merge(y_test2,X_test2,left_index=True,right_index=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exited</th>\n",
       "      <th>pred_result</th>\n",
       "      <th>Ok</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>488</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>172638.13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>678</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120853.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>681</td>\n",
       "      <td>58.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118749.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>633</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82298.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>835</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158043.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164982</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>535</td>\n",
       "      <td>42.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>185660.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>614</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122433.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>729</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171708.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>748</td>\n",
       "      <td>43.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117031.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165032</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>554</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71173.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8122 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Exited  pred_result    Ok  CreditScore   Age  Tenure  Balance  \\\n",
       "46           0            0  True          488  34.0       5        1   \n",
       "69           1            1  True          678  43.0       8        1   \n",
       "110          1            1  True          681  58.0       9        1   \n",
       "128          1            1  True          633  52.0       3        1   \n",
       "145          1            1  True          835  37.0       4        0   \n",
       "...        ...          ...   ...          ...   ...     ...      ...   \n",
       "164982       1            1  True          535  42.0       6        0   \n",
       "164987       0            0  True          614  29.0       7        1   \n",
       "164993       0            0  True          729  35.0       2        1   \n",
       "165001       0            0  True          748  43.0       9        0   \n",
       "165032       0            0  True          554  30.0       7        1   \n",
       "\n",
       "        NumOfProducts  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "46                  2             1.0        172638.13                 0   \n",
       "69                  1             0.0        120853.51                 0   \n",
       "110                 2             0.0        118749.58                 0   \n",
       "128                 1             0.0         82298.81                 0   \n",
       "145                 1             0.0        158043.11                 1   \n",
       "...               ...             ...              ...               ...   \n",
       "164982              1             1.0        185660.30                 1   \n",
       "164987              1             1.0        122433.09                 1   \n",
       "164993              2             0.0        171708.66                 0   \n",
       "165001              1             1.0        117031.20                 1   \n",
       "165032              1             1.0         71173.03                 0   \n",
       "\n",
       "        Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "46                      1                0              0            1  \n",
       "69                      1                0              1            0  \n",
       "110                     1                0              0            1  \n",
       "128                     1                0              1            0  \n",
       "145                     0                0              1            0  \n",
       "...                   ...              ...            ...          ...  \n",
       "164982                  0                0              1            0  \n",
       "164987                  0                0              0            1  \n",
       "164993                  1                0              1            0  \n",
       "165001                  0                0              0            1  \n",
       "165032                  0                1              1            0  \n",
       "\n",
       "[8122 rows x 15 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test2_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Ok', ylabel='count'>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6XElEQVR4nO3de1RVdf7/8dcBPUdQD6RxkUTD1ARFMiw7laZJIlKTZReVUpPsq+E0SqnxG8NbxaSZmaXWmLfCSWvGmiQviIqpaEniNU1NB/vmAaeSo6iAwO+PGc/Xk5cSgYPs52OtvRZ7fz77s99bOvFae3/2Pqby8vJyAQAAGJiHuwsAAABwNwIRAAAwPAIRAAAwPAIRAAAwPAIRAAAwPAIRAAAwPAIRAAAwvDruLuBaUFZWph9//FENGzaUyWRydzkAAOB3KC8v14kTJxQUFCQPj8tfAyIQ/Q4//vijgoOD3V0GAACogCNHjqhp06aX7UMg+h0aNmwo6T//oFar1c3VAACA38PhcCg4ONj5d/xyCES/w7nbZFarlUAEAMA15vdMd2FSNQAAMDwCEQAAMDwCEQAAMDzmEFWi0tJSlZSUuLsMVIG6devK09PT3WUAAKoIgagSlJeXy2636/jx4+4uBVXI19dXgYGBvIsKAGohAlElOBeG/P395e3tzR/MWqa8vFynTp1Sfn6+JKlJkyZurggAUNkIRFeptLTUGYYaN27s7nJQRby8vCRJ+fn58vf35/YZANQyTKq+SufmDHl7e7u5ElS1c79j5okBQO1DIKok3Car/fgdA0DtRSACAACGRyACAACGRyCq5datWyeTyVQrXwkwaNAg9e7d291lAABqAQJRFbvSP9o//PCDzGaz2rVrd8XH6tq1q0aMGOGy7c4779TRo0fl4+NzxeNdyvjx42UymdSzZ88L2qZMmSKTyaSuXbtW2vEAAKhqBKIaZv78+XrsscfkcDi0ZcuWqx7PbDZXycsEmzRporVr1+qHH35w2T537lw1a9asUo9VncrLy3X27Fl3lwEAqGYEomr0ySefKDw8XF5eXmrcuLGioqJUWFjobC8vL9e8efP05JNPqn///nr//fcvGGPjxo3q2rWrvL29dd111yk6Olq//PKLBg0apMzMTE2fPl0mk0kmk0mHDx92uWXmcDjk5eWl5cuXu4y5dOlSNWzYUKdOnZIkHTlyRI899ph8fX3VqFEjPfjggzp8+LDLPv7+/urRo4cWLFjg3LZp0yb9+9//Vmxs7AV1z5kzR6GhoapXr57atGmjmTNnOtsOHz4sk8mkJUuWqHPnzvLy8tJtt92m7777Tl9//bU6duyoBg0aKCYmRseOHbtg7AkTJsjPz09Wq1VDhw5VcXGxs62srEwpKSkKCQmRl5eXIiIi9Mknnzjbz/37LF++XJGRkbJYLNqwYcOlfoUAgFqKFzNWk6NHj6pfv36aPHmyHnroIZ04cUJffvmlysvLnX3Wrl2rU6dOKSoqSjfccIPuvPNOTZs2TfXr15ck5eTkqHv37ho8eLCmT5+uOnXqaO3atSotLdX06dP13XffqV27dpo4caIkyc/PzyXIWK1W3X///Vq0aJFiYmKc21NTU9W7d295e3urpKRE0dHRstls+vLLL1WnTh29/PLL6tmzp3bs2CGz2ezcb/DgwRo9erT+/Oc/S/rP1aG4uLgLzj01NVXJycl6++231aFDB23btk1DhgxR/fr1NXDgQGe/cePG6c0331SzZs00ePBg9e/fXw0bNtT06dPl7e2txx57TMnJyZo1a5Zzn4yMDNWrV0/r1q3T4cOH9dRTT6lx48Z65ZVXJEkpKSn68MMPNXv2bLVq1Urr16/XE088IT8/P91zzz3OcV588UW9/vrratGiha677roK/Y4BXBtyJ4a7uwScp1nyTneXIIlAVG2OHj2qs2fP6uGHH1bz5s0lSeHhrh/K999/X3379pWnp6fatWunFi1a6OOPP9agQYMkSZMnT1bHjh1drq60bdvW+bPZbJa3t7cCAwMvWUdcXJyefPJJnTp1St7e3nI4HEpLS9PSpUslSYsXL1ZZWZnmzJnjvM02b948+fr6at26derRo4dzrPvvv19Dhw7V+vXrFRkZqSVLlmjDhg2aO3euyzHHjRunqVOn6uGHH5YkhYSEaM+ePXr33XddAtELL7yg6OhoSdKf/vQn9evXTxkZGbrrrrskSfHx8Zo/f77L2GazWXPnzpW3t7fatm2riRMnatSoUZo0aZJKSkr06quvavXq1bLZbJKkFi1aaMOGDXr33XddAtHEiRN13333XfLfDQBQuxGIqklERIS6d++u8PBwRUdHq0ePHnrkkUecVyOOHz+uf/zjHy63a5544gm9//77zkCUk5OjRx999Krq6NWrl+rWrat//vOf6tu3r/7+97/LarUqKipKkrR9+3YdOHBADRs2dNnvzJkzOnjwoMu2unXr6oknntC8efP0/fffq3Xr1mrfvr1Ln8LCQh08eFDx8fEaMmSIc/vZs2cvmOh9/r4BAQGSXENjQECA8/vEzomIiHB5S7jNZtPJkyd15MgRnTx5UqdOnbog6BQXF6tDhw4u2zp27HiRfy0AgFEQiKqJp6en0tPTtWnTJq1atUozZszQn//8Z23ZskUhISFatGiRzpw5o06dOjn3KS8vV1lZmb777ju1bt3a+X1aV8NsNuuRRx7RokWL1LdvXy1atEiPP/646tT5z38KJ0+eVGRkpFJTUy/Y18/P74JtgwcPVqdOnbRr1y4NHjz4gvaTJ09Kkv7617+6nJukC74PrG7dus6fz12d+vW2srKy33uqzmOnpaXphhtucGmzWCwu6+duSwIAjIlJ1dXIZDLprrvu0oQJE7Rt2zaZzWbnrar3339fzz//vHJycpzL9u3b1blzZ+ctqPbt2ysjI+OS45vNZpWWlv5mHXFxcVqxYoV2796tNWvWuMz7ufXWW7V//375+/urZcuWLsvFHt1v27at2rZtq127dql///4XtAcEBCgoKEjff//9BeOFhIT8Zq2/Zfv27Tp9+rRzffPmzWrQoIGCg4MVFhYmi8Wi3NzcC44dHBx81ccGANQeXCGqJlu2bFFGRoZ69Oghf39/bdmyRceOHVNoaKhycnL0zTffKDU1VW3atHHZr1+/fpo4caJefvllJSUlKTw8XM8++6yGDh0qs9mstWvX6tFHH9X111+vG2+8UVu2bNHhw4fVoEEDNWrU6KK1dOnSRYGBgYqLi1NISIjLlZu4uDhNmTJFDz74oCZOnKimTZvqX//6l/7xj39o9OjRatq06QXjrVmzRiUlJfL19b3o8SZMmKDnnntOPj4+6tmzp4qKirR161b98ssvSkxMrPg/qv5z+ys+Pl5jx47V4cOHNW7cOA0fPlweHh5q2LChXnjhBY0cOVJlZWW6++67VVBQoI0bN8pqtbrMXwIAGBtXiKqJ1WrV+vXr1atXL7Vu3Vpjx47V1KlTFRMTo/fff19hYWEXhCFJeuihh5Sfn68vvvhCrVu31qpVq7R9+3bdfvvtstls+uyzz5y3u1544QV5enoqLCxMfn5+ys3NvWgtJpNJ/fr10/bt2y94Kszb21vr169Xs2bN9PDDDys0NFTx8fE6c+aMrFbrRcerX7/+JcOQJD399NOaM2eO5s2bp/DwcN1zzz2aP39+pVwh6t69u1q1aqUuXbro8ccf1x/+8AeNHz/e2T5p0iS99NJLSklJUWhoqHr27Km0tLRKOTYAoPYwlZ//3DcuyuFwyMfHRwUFBReEgjNnzujQoUMKCQlRvXr13FQhqgO/a6B24LH7mqUqH7u/3N/vX+MKEQAAMDwCEQAAMDwCEQAAMDwCEQAAMDwCEQAAMDwCEQAAMDy3BqJZs2apffv2slqtslqtstlsWr58ubO9a9euMplMLsvQoUNdxsjNzVVsbKy8vb3l7++vUaNG6ezZsy591q1bp1tvvVUWi0UtW7a84AtCAQCAsbn1TdVNmzbVX/7yF7Vq1Url5eVasGCBHnzwQW3bts35Le5DhgzRxIkTnfuc/0WepaWlio2NVWBgoDZt2qSjR49qwIABqlu3rl599VVJ0qFDhxQbG6uhQ4cqNTVVGRkZevrpp9WkSRPnN6sDAABjc2sgeuCBB1zWX3nlFc2aNUubN292BiJvb28FBgZedP9Vq1Zpz549Wr16tQICAnTLLbdo0qRJGjNmjMaPHy+z2azZs2crJCREU6dOlSSFhoZqw4YNmjZtGoEIAABIqkHfZVZaWqqPP/5YhYWFstlszu2pqan68MMPFRgYqAceeEAvvfSS8ypRVlaWwsPDFRAQ4OwfHR2tYcOGaffu3erQoYOysrIUFRXlcqzo6GiNGDHikrUUFRWpqKjIue5wOCrpLCtf5KiF1Xq87CkDKrTfO++8oylTpshutysiIkIzZszQ7bfffsn+H3/8sV566SUdPnxYrVq10muvvaZevXpVtGwAAC7L7ZOqd+7cqQYNGshisWjo0KFaunSpwsLCJEn9+/fXhx9+qLVr1yopKUkffPCBnnjiCee+drvdJQxJcq7b7fbL9nE4HC7fkn6+lJQU+fj4OBe+Gf3qLF68WImJiRo3bpy++eYbRUREKDo6Wvn5+Rftv2nTJvXr10/x8fHatm2bevfurd69e2vXrl3VXDkAwCjcHohuvvlm5eTkaMuWLRo2bJgGDhyoPXv2SJKeeeYZRUdHKzw8XHFxcVq4cKGWLl2qgwcPVmlNSUlJKigocC5Hjhyp0uPVdm+88YaGDBmip556SmFhYZo9e7a8vb01d+7ci/afPn26evbsqVGjRik0NFSTJk3SrbfeqrfffruaKwcAGIXbA5HZbFbLli0VGRmplJQURUREaPr06Rft26lTJ0nSgQMHJEmBgYHKy8tz6XNu/dy8o0v1sVqt8vLyuuhxLBaL88m3cwsqpri4WNnZ2S63LT08PBQVFaWsrKyL7nOp25yX6g8AwNVyeyD6tbKyMpf5O+fLycmRJDVp0kSSZLPZtHPnTpdbL+np6bJarc7bbjabTRkZGS7jpKenu8xTQtX597//rdLS0ovetjx3W/PXLnWb81L9AQC4Wm6dVJ2UlKSYmBg1a9ZMJ06c0KJFi7Ru3TqtXLlSBw8e1KJFi9SrVy81btxYO3bs0MiRI9WlSxe1b99ektSjRw+FhYXpySef1OTJk2W32zV27FglJCTIYrFIkoYOHaq3335bo0eP1uDBg7VmzRotWbJEaWlp7jx1AABQg7g1EOXn52vAgAE6evSofHx81L59e61cuVL33Xefjhw5otWrV+vNN99UYWGhgoOD1adPH40dO9a5v6enp5YtW6Zhw4bJZrOpfv36GjhwoMt7i0JCQpSWlqaRI0dq+vTpatq0qebMmcMj99Xk+uuvl6en50VvW17qdQqXus15qf4AAFwttwai999//5JtwcHByszM/M0xmjdvri+++OKyfbp27apt27ZdcX24emazWZGRkcrIyFDv3r0l/ee2aEZGhoYPH37Rfc7d5jz/1Qjc5gQAVKUa8x4i1F6JiYkaOHCgOnbsqNtvv9151e+pp56SJA0YMEA33HCDUlJSJEl/+tOfdM8992jq1KmKjY3VRx99pK1bt+q9995z52kAAGoxAhGq3OOPP65jx44pOTlZdrtdt9xyi1asWOGcOJ2bmysPj/+b33/nnXdq0aJFGjt2rP7f//t/atWqlT799FO1a9fOXacAAKjlTOXl5eXuLqKmczgc8vHxUUFBwQWP4J85c0aHDh1SSEiI6tWr56YKUR34XQO1Q+7EcHeXgPM0S95ZZWNf7u/3r9W4x+4BAACqG4EIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHt9ldo2r7lfQV+QV6+vXr9eUKVOUnZ2to0ePaunSper932++v5R169YpMTFRu3fvVnBwsMaOHatBgwZVrGgAAH4DV4hQ5QoLCxUREaF33nnnd/U/dOiQYmNj1a1bN+Xk5GjEiBF6+umntXLlyiquFABgVFwhQpWLiYlRTEzM7+4/e/ZshYSEaOrUqZKk0NBQbdiwQdOmTVN0dHRVlQkAMDCuEKHGycrKUlRUlMu26OhoZWVluakiAEBtRyBCjWO32xUQEOCyLSAgQA6HQ6dPn3ZTVQCA2oxABAAADI9AhBonMDBQeXl5Ltvy8vJktVrl5eXlpqoAALUZgQg1js1mU0ZGhsu29PR02Ww2N1UEAKjtCESocidPnlROTo5ycnIk/eex+pycHOXm5kqSkpKSNGDAAGf/oUOH6vvvv9fo0aO1d+9ezZw5U0uWLNHIkSPdUT4AwAAIRKhyW7duVYcOHdShQwdJUmJiojp06KDk5GRJ0tGjR53hSJJCQkKUlpam9PR0RUREaOrUqZozZw6P3AMAqgzvIbrGVeTN0dWta9euKi8vv2T7/PnzL7rPtm3bqrAqoHpFjlro7hLwX0sbursC1ERcIQIAAIZHIAIAAIZHIAIAAIZHIAIAAIZHIKokl5s0jNqB3zEA1F4EoqtUt25dSdKpU6fcXAmq2rnf8bnfOQCg9uCx+6vk6ekpX19f5efnS5K8vb1lMpncXBUqU3l5uU6dOqX8/Hz5+vrK09PT3SUBACoZgagSBAYGSpIzFKF28vX1df6uAQC1C4GoEphMJjVp0kT+/v4qKSlxdzmoAnXr1uXKEADUYgSiSuTp6ckfTQAArkFMqgYAAIZHIAIAAIZHIAIAAIbn1kA0a9YstW/fXlarVVarVTabTcuXL3e2nzlzRgkJCWrcuLEaNGigPn36KC8vz2WM3NxcxcbGytvbW/7+/ho1apTOnj3r0mfdunW69dZbZbFY1LJly4t+uzoAADAutwaipk2b6i9/+Yuys7O1detW3XvvvXrwwQe1e/duSdLIkSP1+eef6+OPP1ZmZqZ+/PFHPfzww879S0tLFRsbq+LiYm3atEkLFizQ/PnzlZyc7Oxz6NAhxcbGqlu3bsrJydGIESP09NNPa+XKldV+vgAAoGYyldew7yNo1KiRpkyZokceeUR+fn5atGiRHnnkEUnS3r17FRoaqqysLN1xxx1avny57r//fv34448KCAiQJM2ePVtjxozRsWPHZDabNWbMGKWlpWnXrl3OY/Tt21fHjx/XihUrfldNDodDPj4+KigokNVqrfyTBlDrRY5a6O4S8F9LG05xdwk4T7PknVU29pX8/a4xc4hKS0v10UcfqbCwUDabTdnZ2SopKVFUVJSzT5s2bdSsWTNlZWVJkrKyshQeHu4MQ5IUHR0th8PhvMqUlZXlMsa5PufGuJiioiI5HA6XBQAA1F5uD0Q7d+5UgwYNZLFYNHToUC1dulRhYWGy2+0ym83y9fV16R8QECC73S5JstvtLmHoXPu5tsv1cTgcOn369EVrSklJkY+Pj3MJDg6ujFMFAAA1lNsD0c0336ycnBxt2bJFw4YN08CBA7Vnzx631pSUlKSCggLncuTIEbfWAwAAqpbb31RtNpvVsmVLSVJkZKS+/vprTZ8+XY8//riKi4t1/Phxl6tEeXl5zu+TCgwM1FdffeUy3rmn0M7v8+sn0/Ly8mS1WuXl5XXRmiwWiywWS6WcHwAAqPncfoXo18rKylRUVKTIyEjVrVtXGRkZzrZ9+/YpNzdXNptNkmSz2bRz506XL1VNT0+X1WpVWFiYs8/5Y5zrc24MAAAAt14hSkpKUkxMjJo1a6YTJ05o0aJFWrdunVauXCkfHx/Fx8crMTFRjRo1ktVq1R//+EfZbDbdcccdkqQePXooLCxMTz75pCZPniy73a6xY8cqISHBeYVn6NChevvttzV69GgNHjxYa9as0ZIlS5SWlubOUwcAADWIWwNRfn6+BgwYoKNHj8rHx0ft27fXypUrdd9990mSpk2bJg8PD/Xp00dFRUWKjo7WzJkznft7enpq2bJlGjZsmGw2m+rXr6+BAwdq4sSJzj4hISFKS0vTyJEjNX36dDVt2lRz5sxRdHR0tZ8vAAComWrce4hqIt5DBOBq8R6imoP3ENUsvIcIAACghiAQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAwyMQAQAAw3NrIEpJSdFtt92mhg0byt/fX71799a+fftc+nTt2lUmk8llGTp0qEuf3NxcxcbGytvbW/7+/ho1apTOnj3r0mfdunW69dZbZbFY1LJlS82fP7+qTw8AAFwj3BqIMjMzlZCQoM2bNys9PV0lJSXq0aOHCgsLXfoNGTJER48edS6TJ092tpWWlio2NlbFxcXatGmTFixYoPnz5ys5OdnZ59ChQ4qNjVW3bt2Uk5OjESNG6Omnn9bKlSur7VwBAEDNVcedB1+xYoXL+vz58+Xv76/s7Gx16dLFud3b21uBgYEXHWPVqlXas2ePVq9erYCAAN1yyy2aNGmSxowZo/Hjx8tsNmv27NkKCQnR1KlTJUmhoaHasGGDpk2bpujo6AvGLCoqUlFRkXPd4XBUxukCAIAaqkbNISooKJAkNWrUyGV7amqqrr/+erVr105JSUk6deqUsy0rK0vh4eEKCAhwbouOjpbD4dDu3budfaKiolzGjI6OVlZW1kXrSElJkY+Pj3MJDg6ulPMDAAA1k1uvEJ2vrKxMI0aM0F133aV27do5t/fv31/NmzdXUFCQduzYoTFjxmjfvn36xz/+IUmy2+0uYUiSc91ut1+2j8Ph0OnTp+Xl5eXSlpSUpMTEROe6w+EgFAEAUIvVmECUkJCgXbt2acOGDS7bn3nmGefP4eHhatKkibp3766DBw/qpptuqpJaLBaLLBZLlYwNAABqnhpxy2z48OFatmyZ1q5dq6ZNm162b6dOnSRJBw4ckCQFBgYqLy/Ppc+59XPzji7Vx2q1XnB1CAAAGI9bA1F5ebmGDx+upUuXas2aNQoJCfnNfXJyciRJTZo0kSTZbDbt3LlT+fn5zj7p6emyWq0KCwtz9snIyHAZJz09XTabrZLOBAAAXMvcGogSEhL04YcfatGiRWrYsKHsdrvsdrtOnz4tSTp48KAmTZqk7OxsHT58WP/85z81YMAAdenSRe3bt5ck9ejRQ2FhYXryySe1fft2rVy5UmPHjlVCQoLzttfQoUP1/fffa/To0dq7d69mzpypJUuWaOTIkW47dwAAUHO4NRDNmjVLBQUF6tq1q5o0aeJcFi9eLEkym81avXq1evTooTZt2uj5559Xnz599PnnnzvH8PT01LJly+Tp6SmbzaYnnnhCAwYM0MSJE519QkJClJaWpvT0dEVERGjq1KmaM2fORR+5BwAAxuPWSdXl5eWXbQ8ODlZmZuZvjtO8eXN98cUXl+3TtWtXbdu27YrqAwAAxlAjJlUDAAC4E4EIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYHoEIAAAYXoUC0b333qvjx49fsN3hcOjee++92poAAACqVYUC0bp161RcXHzB9jNnzujLL7+86qIAAACqU50r6bxjxw7nz3v27JHdbneul5aWasWKFbrhhhsqrzoAAIBqcEWB6JZbbpHJZJLJZLrorTEvLy/NmDGj0ooDAACoDlcUiA4dOqTy8nK1aNFCX331lfz8/JxtZrNZ/v7+8vT0rPQiAQAAqtIVBaLmzZtLksrKyqqkGAAAAHe4okB0vv3792vt2rXKz8+/ICAlJydfdWEAAADVpUJPmf31r39VaGiokpOT9cknn2jp0qXO5dNPP/3d46SkpOi2225Tw4YN5e/vr969e2vfvn0ufc6cOaOEhAQ1btxYDRo0UJ8+fZSXl+fSJzc3V7GxsfL29pa/v79GjRqls2fPuvRZt26dbr31VlksFrVs2VLz58+vyKkDAIBaqEKB6OWXX9Yrr7wiu92unJwcbdu2zbl88803v3uczMxMJSQkaPPmzUpPT1dJSYl69OihwsJCZ5+RI0fq888/18cff6zMzEz9+OOPevjhh53tpaWlio2NVXFxsTZt2qQFCxZo/vz5LlepDh06pNjYWHXr1k05OTkaMWKEnn76aa1cubIipw8AAGoZU3l5efmV7mS1WpWTk6MWLVpUajHHjh2Tv7+/MjMz1aVLFxUUFMjPz0+LFi3SI488Iknau3evQkNDlZWVpTvuuEPLly/X/fffrx9//FEBAQGSpNmzZ2vMmDE6duyYzGazxowZo7S0NO3atct5rL59++r48eNasWLFb9blcDjk4+OjgoICWa3WSj1nAMYQOWqhu0vAfy1tOMXdJeA8zZJ3VtnYV/L3u0JXiB599FGtWrWqQsVdTkFBgSSpUaNGkqTs7GyVlJQoKirK2adNmzZq1qyZsrKyJElZWVkKDw93hiFJio6OlsPh0O7du519zh/jXJ9zY/xaUVGRHA6HywIAAGqvCk2qbtmypV566SVt3rxZ4eHhqlu3rkv7c889d8VjlpWVacSIEbrrrrvUrl07SZLdbpfZbJavr69L34CAAOdLIe12u0sYOtd+ru1yfRwOh06fPi0vLy+XtpSUFE2YMOGKzwEAAFybKhSI3nvvPTVo0ECZmZnKzMx0aTOZTBUKRAkJCdq1a5c2bNhQkZIqVVJSkhITE53rDodDwcHBbqwIAABUpQoFokOHDlVqEcOHD9eyZcu0fv16NW3a1Lk9MDBQxcXFOn78uMtVory8PAUGBjr7fPXVVy7jnXsK7fw+v34yLS8vT1ar9YKrQ5JksVhksVgq5dwAAEDNV6E5RJWlvLxcw4cP19KlS7VmzRqFhIS4tEdGRqpu3brKyMhwbtu3b59yc3Nls9kkSTabTTt37lR+fr6zT3p6uqxWq8LCwpx9zh/jXJ9zYwAAAGOr0BWiwYMHX7Z97ty5v2uchIQELVq0SJ999pkaNmzonPPj4+MjLy8v+fj4KD4+XomJiWrUqJGsVqv++Mc/ymaz6Y477pAk9ejRQ2FhYXryySc1efJk2e12jR07VgkJCc6rPEOHDtXbb7+t0aNHa/DgwVqzZo2WLFmitLS0ipw+AACoZSoUiH755ReX9ZKSEu3atUvHjx+/6Je+XsqsWbMkSV27dnXZPm/ePA0aNEiSNG3aNHl4eKhPnz4qKipSdHS0Zs6c6ezr6empZcuWadiwYbLZbKpfv74GDhyoiRMnOvuEhIQoLS1NI0eO1PTp09W0aVPNmTNH0dHRV3jmAACgNqrQe4gupqysTMOGDdNNN92k0aNHV8aQNQbvIQJwtXgPUc3Be4hqlmv6PUQXHcjDQ4mJiZo2bVplDQkAAFAtKnVS9cGDBy/4DjEAAICarkJziM5/R4/0n6fFjh49qrS0NA0cOLBSCgMAAKguFQpE27Ztc1n38PCQn5+fpk6d+ptPoAEAANQ0FQpEa9eurew6AAAA3KZCgeicY8eOad++fZKkm2++WX5+fpVSFAAAQHWq0KTqwsJCDR48WE2aNFGXLl3UpUsXBQUFKT4+XqdOnarsGgEAAKpUhQJRYmKiMjMz9fnnn+v48eM6fvy4PvvsM2VmZur555+v7BoBAACqVIVumf3973/XJ5984vKG6V69esnLy0uPPfaY8w3UAAAA14IKXSE6deqUAgICLtju7+/PLTMAAHDNqVAgstlsGjdunM6cOePcdvr0aU2YMIFvkAcAANecCt0ye/PNN9WzZ081bdpUERERkqTt27fLYrFo1apVlVogAABAVatQIAoPD9f+/fuVmpqqvXv3SpL69eunuLg4eXl5VWqBAAAAVa1CgSglJUUBAQEaMmSIy/a5c+fq2LFjGjNmTKUUBwAAUB0qNIfo3XffVZs2bS7Y3rZtW82ePfuqiwIAAKhOFQpEdrtdTZo0uWC7n5+fjh49etVFAQAAVKcKBaLg4GBt3Ljxgu0bN25UUFDQVRcFAABQnSo0h2jIkCEaMWKESkpKdO+990qSMjIyNHr0aN5UDQAArjkVCkSjRo3STz/9pGeffVbFxcWSpHr16mnMmDFKSkqq1AIBAACqWoUCkclk0muvvaaXXnpJ3377rby8vNSqVStZLJbKrg8AAKDKVSgQndOgQQPddtttlVULAACAW1RoUjUAAEBtQiACAACGRyACAACGRyACAACGRyACAACGRyACAACGRyACAACGRyACAACGRyACAACGRyACAACGRyACAACGRyACAACGRyACAACGRyACAACGRyACAACGRyACAACG59ZAtH79ej3wwAMKCgqSyWTSp59+6tI+aNAgmUwml6Vnz54ufX7++WfFxcXJarXK19dX8fHxOnnypEufHTt2qHPnzqpXr56Cg4M1efLkqj41AABwDXFrICosLFRERITeeeedS/bp2bOnjh496lz+9re/ubTHxcVp9+7dSk9P17Jly7R+/Xo988wzznaHw6EePXqoefPmys7O1pQpUzR+/Hi99957VXZeAADg2lLHnQePiYlRTEzMZftYLBYFBgZetO3bb7/VihUr9PXXX6tjx46SpBkzZqhXr156/fXXFRQUpNTUVBUXF2vu3Lkym81q27atcnJy9MYbb7gEJwAAYFw1fg7RunXr5O/vr5tvvlnDhg3TTz/95GzLysqSr6+vMwxJUlRUlDw8PLRlyxZnny5dushsNjv7REdHa9++ffrll18uesyioiI5HA6XBQAA1F41OhD17NlTCxcuVEZGhl577TVlZmYqJiZGpaWlkiS73S5/f3+XferUqaNGjRrJbrc7+wQEBLj0Obd+rs+vpaSkyMfHx7kEBwdX9qkBAIAaxK23zH5L3759nT+Hh4erffv2uummm7Ru3Tp17969yo6blJSkxMRE57rD4SAUAQBQi9XoK0S/1qJFC11//fU6cOCAJCkwMFD5+fkufc6ePauff/7ZOe8oMDBQeXl5Ln3OrV9qbpLFYpHVanVZAABA7XVNBaIffvhBP/30k5o0aSJJstlsOn78uLKzs5191qxZo7KyMnXq1MnZZ/369SopKXH2SU9P180336zrrruuek8AAADUSG4NRCdPnlROTo5ycnIkSYcOHVJOTo5yc3N18uRJjRo1Sps3b9bhw4eVkZGhBx98UC1btlR0dLQkKTQ0VD179tSQIUP01VdfaePGjRo+fLj69u2roKAgSVL//v1lNpsVHx+v3bt3a/HixZo+fbrLLTEAAGBsbg1EW7duVYcOHdShQwdJUmJiojp06KDk5GR5enpqx44d+sMf/qDWrVsrPj5ekZGR+vLLL2WxWJxjpKamqk2bNurevbt69eqlu+++2+UdQz4+Plq1apUOHTqkyMhIPf/880pOTuaRewAA4GQqLy8vd3cRNZ3D4ZCPj48KCgqYTwSgQiJHLXR3CfivpQ2nuLsEnKdZ8s4qG/tK/n5fU3OIAAAAqgKBCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGB6BCAAAGJ5bA9H69ev1wAMPKCgoSCaTSZ9++qlLe3l5uZKTk9WkSRN5eXkpKipK+/fvd+nz888/Ky4uTlarVb6+voqPj9fJkydd+uzYsUOdO3dWvXr1FBwcrMmTJ1f1qQEAgGuIWwNRYWGhIiIi9M4771y0ffLkyXrrrbc0e/ZsbdmyRfXr11d0dLTOnDnj7BMXF6fdu3crPT1dy5Yt0/r16/XMM8842x0Oh3r06KHmzZsrOztbU6ZM0fjx4/Xee+9V+fkBAIBrQx13HjwmJkYxMTEXbSsvL9ebb76psWPH6sEHH5QkLVy4UAEBAfr000/Vt29fffvtt1qxYoW+/vprdezYUZI0Y8YM9erVS6+//rqCgoKUmpqq4uJizZ07V2azWW3btlVOTo7eeOMNl+B0vqKiIhUVFTnXHQ5HJZ85AACoSWrsHKJDhw7JbrcrKirKuc3Hx0edOnVSVlaWJCkrK0u+vr7OMCRJUVFR8vDw0JYtW5x9unTpIrPZ7OwTHR2tffv26ZdffrnosVNSUuTj4+NcgoODq+IUAQBADVFjA5HdbpckBQQEuGwPCAhwttntdvn7+7u016lTR40aNXLpc7Exzj/GryUlJamgoMC5HDly5OpPCAAA1FhuvWVWU1ksFlksFneXAQAAqkmNvUIUGBgoScrLy3PZnpeX52wLDAxUfn6+S/vZs2f1888/u/S52BjnHwMAABhbjQ1EISEhCgwMVEZGhnObw+HQli1bZLPZJEk2m03Hjx9Xdna2s8+aNWtUVlamTp06OfusX79eJSUlzj7p6em6+eabdd1111XT2QAAgJrMrYHo5MmTysnJUU5OjqT/TKTOyclRbm6uTCaTRowYoZdffln//Oc/tXPnTg0YMEBBQUHq3bu3JCk0NFQ9e/bUkCFD9NVXX2njxo0aPny4+vbtq6CgIElS//79ZTabFR8fr927d2vx4sWaPn26EhMT3XTWAACgpnHrHKKtW7eqW7duzvVzIWXgwIGaP3++Ro8ercLCQj3zzDM6fvy47r77bq1YsUL16tVz7pOamqrhw4ere/fu8vDwUJ8+ffTWW2852318fLRq1SolJCQoMjJS119/vZKTky/5yD0AADAeU3l5ebm7i6jpHA6HfHx8VFBQIKvV6u5yAFyDIkctdHcJ+K+lDae4uwScp1nyziob+0r+ftfYOUQAAADVhUAEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMj0AEAAAMr467C8D/iRy10N0l4L+ypwxwdwkAgGrEFSIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4BCIAAGB4NToQjR8/XiaTyWVp06aNs/3MmTNKSEhQ48aN1aBBA/Xp00d5eXkuY+Tm5io2Nlbe3t7y9/fXqFGjdPbs2eo+FQAAUIPVcXcBv6Vt27ZavXq1c71Onf8reeTIkUpLS9PHH38sHx8fDR8+XA8//LA2btwoSSotLVVsbKwCAwO1adMmHT16VAMGDFDdunX16quvVvu5AACAmqnGB6I6deooMDDwgu0FBQV6//33tWjRIt17772SpHnz5ik0NFSbN2/WHXfcoVWrVmnPnj1avXq1AgICdMstt2jSpEkaM2aMxo8fL7PZXN2ng2tE7sRwd5eA8zRL3unuEgDUcjX6lpkk7d+/X0FBQWrRooXi4uKUm5srScrOzlZJSYmioqKcfdu0aaNmzZopKytLkpSVlaXw8HAFBAQ4+0RHR8vhcGj37t2XPGZRUZEcDofLAgAAaq8aHYg6deqk+fPna8WKFZo1a5YOHTqkzp0768SJE7Lb7TKbzfL19XXZJyAgQHa7XZJkt9tdwtC59nNtl5KSkiIfHx/nEhwcXLknBgAAapQafcssJibG+XP79u3VqVMnNW/eXEuWLJGXl1eVHTcpKUmJiYnOdYfDQSgCAKAWq9FXiH7N19dXrVu31oEDBxQYGKji4mIdP37cpU9eXp5zzlFgYOAFT52dW7/YvKRzLBaLrFarywIAAGqvayoQnTx5UgcPHlSTJk0UGRmpunXrKiMjw9m+b98+5ebmymazSZJsNpt27typ/Px8Z5/09HRZrVaFhYVVe/0AAKBmqtG3zF544QU98MADat68uX788UeNGzdOnp6e6tevn3x8fBQfH6/ExEQ1atRIVqtVf/zjH2Wz2XTHHXdIknr06KGwsDA9+eSTmjx5sux2u8aOHauEhARZLBY3nx0AAKgpanQg+uGHH9SvXz/99NNP8vPz0913363NmzfLz89PkjRt2jR5eHioT58+KioqUnR0tGbOnOnc39PTU8uWLdOwYcNks9lUv359DRw4UBMnTnTXKQEAgBqoRgeijz766LLt9erV0zvvvKN33nnnkn2aN2+uL774orJLAwAAtcg1NYcIAACgKhCIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RGIAACA4RkqEL3zzju68cYbVa9ePXXq1ElfffWVu0sCAAA1gGEC0eLFi5WYmKhx48bpm2++UUREhKKjo5Wfn+/u0gAAgJsZJhC98cYbGjJkiJ566imFhYVp9uzZ8vb21ty5c91dGgAAcLM67i6gOhQXFys7O1tJSUnObR4eHoqKilJWVtYF/YuKilRUVORcLygokCQ5HI4qrbO06HSVjo/f70TdUneXgPNU9WevOvD5rjn4fNcsVfn5Pjd2eXn5b/Y1RCD697//rdLSUgUEBLhsDwgI0N69ey/on5KSogkTJlywPTg4uMpqRM3Szt0FwFWKj7srQC3C57uGqYbP94kTJ+Tjc/njGCIQXamkpCQlJiY618vKyvTzzz+rcePGMplMbqwM1cHhcCg4OFhHjhyR1Wp1dzkAKhGfb2MpLy/XiRMnFBQU9Jt9DRGIrr/+enl6eiovL89le15engIDAy/ob7FYZLFYXLb5+vpWZYmogaxWK//DBGopPt/G8VtXhs4xxKRqs9msyMhIZWRkOLeVlZUpIyNDNpvNjZUBAICawBBXiCQpMTFRAwcOVMeOHXX77bfrzTffVGFhoZ566il3lwYAANzMMIHo8ccf17Fjx5ScnCy73a5bbrlFK1asuGCiNWCxWDRu3LgLbpsCuPbx+calmMp/z7NoAAAAtZgh5hABAABcDoEIAAAYHoEIAAAYHoEIOM/8+fN55xQAGBCBCLXSoEGDZDKZLlgOHDjg7tIAVJKLfcbPX8aPH+/uEnENMcxj9zCenj17at68eS7b/Pz83FQNgMp29OhR58+LFy9WcnKy9u3b59zWoEED58/l5eUqLS1VnTr82cPFcYUItZbFYlFgYKDLMn36dIWHh6t+/foKDg7Ws88+q5MnT15yjO3bt6tbt25q2LChrFarIiMjtXXrVmf7hg0b1LlzZ3l5eSk4OFjPPfecCgsLq+P0AMM7/7Pt4+Mjk8nkXN+7d68aNmyo5cuXKzIyUhaLRRs2bNCgQYPUu3dvl3FGjBihrl27OtfLysqUkpKikJAQeXl5KSIiQp988kn1nhyqHYEIhuLh4aG33npLu3fv1oIFC7RmzRqNHj36kv3j4uLUtGlTff3118rOztaLL76ounXrSpIOHjyonj17qk+fPtqxY4cWL16sDRs2aPjw4dV1OgB+w4svvqi//OUv+vbbb9W+ffvftU9KSooWLlyo2bNna/fu3Ro5cqSeeOIJZWZmVnG1cCeuHaLWWrZsmcsl85iYGH388cfO9RtvvFEvv/yyhg4dqpkzZ150jNzcXI0aNUpt2rSRJLVq1crZlpKSori4OI0YMcLZ9tZbb+mee+7RrFmzVK9evSo4KwBXYuLEibrvvvt+d/+ioiK9+uqrWr16tfO7Llu0aKENGzbo3Xff1T333FNVpcLNCESotbp166ZZs2Y51+vXr6/Vq1crJSVFe/fulcPh0NmzZ3XmzBmdOnVK3t7eF4yRmJiop59+Wh988IGioqL06KOP6qabbpL0n9tpO3bsUGpqqrN/eXm5ysrKdOjQIYWGhlb9SQK4rI4dO15R/wMHDujUqVMXhKji4mJ16NChMktDDUMgQq1Vv359tWzZ0rl++PBh3X///Ro2bJheeeUVNWrUSBs2bFB8fLyKi4svGojGjx+v/v37Ky0tTcuXL9e4ceP00Ucf6aGHHtLJkyf1P//zP3ruuecu2K9Zs2ZVem4Afp/69eu7rHt4eOjX31hVUlLi/PncnMK0tDTdcMMNLv34/rPajUAEw8jOzlZZWZmmTp0qD4//TJ9bsmTJb+7XunVrtW7dWiNHjlS/fv00b948PfTQQ7r11lu1Z88el9AFoGbz8/PTrl27XLbl5OQ45waGhYXJYrEoNzeX22MGw6RqGEbLli1VUlKiGTNm6Pvvv9cHH3yg2bNnX7L/6dOnNXz4cK1bt07/+te/tHHjRn399dfOW2FjxozRpk2bNHz4cOXk5Gj//v367LPPmFQN1GD33nuvtm7dqoULF2r//v0aN26cS0Bq2LChXnjhBY0cOVILFizQwYMH9c0332jGjBlasGCBGytHVSMQwTAiIiL0xhtv6LXXXlO7du2UmpqqlJSUS/b39PTUTz/9pAEDBqh169Z67LHHFBMTowkTJkiS2rdvr8zMTH333Xfq3LmzOnTooOTkZAUFBVXXKQG4QtHR0XrppZc0evRo3XbbbTpx4oQGDBjg0mfSpEl66aWXlJKSotDQUPXs2VNpaWkKCQlxU9WoDqbyX99MBQAAMBiuEAEAAMMjEAEAAMMjEAEAAMMjEAEAAMMjEAEAAMMjEAEAAMMjEAEAAMMjEAEAAMMjEAHAeW688Ua9+eab7i4DQDUjEAEwjCNHjmjw4MEKCgqS2WxW8+bN9ac//Uk//fSTu0sD4GYEIgCG8P3336tjx47av3+//va3v+nAgQOaPXu2MjIyZLPZ9PPPP7u7RABuRCACYAgJCQkym81atWqV7rnnHjVr1kwxMTFavXq1/vd//1d//vOfL7rfnDlz5Ovrq4yMjGquGEB1IhABqPV+/vlnrVy5Us8++6y8vLxc2gIDAxUXF6fFixfr1991PXnyZL344otatWqVunfvXp0lA6hmddxdAABUtf3796u8vFyhoaEXbQ8NDdUvv/yiY8eOObeNGTNGH3zwgTIzM9W2bdvqKhWAmxCIABjGr68AXcrUqVNVWFiorVu3qkWLFlVcFYCagFtmAGq9li1bymQy6dtvv71o+7fffqvrrrtOfn5+kqTOnTurtLRUS5Ysqc4yAbgRgQhArde4cWPdd999mjlzpk6fPu3SZrfblZqaqscff1wmk0mSdPvtt2v58uV69dVX9frrr7ujZADVjEAEwBDefvttFRUVKTo6WuvXr9eRI0e0YsUK3Xfffbrhhhv0yiuvuPS/88479cUXX2jChAm8qBEwAAIRAENo1aqVc07QY489pptuuknPPPOMunXrpqysLDVq1OiCfe6++26lpaVp7NixmjFjhhuqBlBdTOW/d5YhAABALcUVIgAAYHgEIgAAYHgEIgAAYHgEIgAAYHgEIgAAYHgEIgAAYHgEIgAAYHgEIgAAYHgEIgAAYHgEIgAAYHgEIgAAYHj/H5Qxe6gA3D5bAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_test2_final,x='Ok',hue='IsActiveMember')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>602</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135082.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>559</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180890.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>773</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87549.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>616</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59346.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>797</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62402.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165019</th>\n",
       "      <td>719</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77500.48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165021</th>\n",
       "      <td>632</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128528.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165022</th>\n",
       "      <td>577</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148811.14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165030</th>\n",
       "      <td>792</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131834.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165032</th>\n",
       "      <td>554</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71173.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40606 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore   Age  Tenure  Balance  NumOfProducts  IsActiveMember  \\\n",
       "16              602  36.0       7        0              2             1.0   \n",
       "19              559  61.0       1        1              1             1.0   \n",
       "20              773  35.0       9        0              2             1.0   \n",
       "26              616  31.0       3        1              2             1.0   \n",
       "32              797  55.0       0        1              2             1.0   \n",
       "...             ...   ...     ...      ...            ...             ...   \n",
       "165019          719  32.0       6        1              1             1.0   \n",
       "165021          632  41.0       6        0              2             1.0   \n",
       "165022          577  45.0       2        0              1             0.0   \n",
       "165030          792  35.0       3        0              1             0.0   \n",
       "165032          554  30.0       7        1              1             1.0   \n",
       "\n",
       "        EstimatedSalary  Geography_France  Geography_Germany  Geography_Spain  \\\n",
       "16            135082.47                 1                  0                0   \n",
       "19            180890.40                 1                  0                0   \n",
       "20             87549.36                 0                  0                1   \n",
       "26             59346.40                 0                  0                1   \n",
       "32             62402.38                 0                  0                1   \n",
       "...                 ...               ...                ...              ...   \n",
       "165019         77500.48                 1                  0                0   \n",
       "165021        128528.83                 0                  0                1   \n",
       "165022        148811.14                 1                  0                0   \n",
       "165030        131834.45                 1                  0                0   \n",
       "165032         71173.03                 0                  0                1   \n",
       "\n",
       "        Gender_Female  Gender_Male  \n",
       "16                  0            1  \n",
       "19                  0            1  \n",
       "20                  0            1  \n",
       "26                  0            1  \n",
       "32                  1            0  \n",
       "...               ...          ...  \n",
       "165019              1            0  \n",
       "165021              1            0  \n",
       "165022              1            0  \n",
       "165030              0            1  \n",
       "165032              1            0  \n",
       "\n",
       "[40606 rows x 12 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train3 = df_train2[df_train2['IsActiveMember'] == 1]\n",
    "df_train2 = df_train2[df_train2['IsActiveMember'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df_train2.drop(columns=['Exited','HasCrCard','IsActiveMember'])\n",
    "y2 = df_train2.Exited\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2,test_size=0.2,stratify=y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = df_train3.drop(columns=['Exited','HasCrCard','IsActiveMember'])\n",
    "y3 = df_train3.Exited\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3,y3,test_size=0.2,stratify=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado el analisis de XGBoost\n",
      "\n",
      "{'Model': 'XGBoost', 'Best_Params': {'booster': 'gbtree', 'eta': 0.05, 'max_depth': 5, 'n_estimators': 50}, 'Test_Accuracy': 0.805852417302799}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Params</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'booster': 'gbtree', 'eta': 0.05, 'max_depth'...</td>\n",
       "      <td>0.805852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model                                        Best_Params  Test_Accuracy\n",
       "0  XGBoost  {'booster': 'gbtree', 'eta': 0.05, 'max_depth'...       0.805852"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    #'LightGBM': LGBMClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    #'RandomForest': RandomForestClassifier(),\n",
    "    #'GradientBoosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    #'LightGBM':{'n_estimators': [10,30,50, 100, 200],'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "    'XGBoost': {'n_estimators': [ 30,50,70], 'max_depth': [5, 7,10],'booster':['gbtree'],'eta':[0.1,0.05]},\n",
    "    #'RandomForest': {'n_estimators': [50], 'max_depth': [None, 10]},\n",
    "    #'GradientBoosting': {'n_estimators': [50], 'max_depth': [3, 7]}\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train2, y_train2)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    y_pred2 = grid_search.predict(X_test2)\n",
    "    accuracy = accuracy_score(y_test2, y_pred2)\n",
    "\n",
    "    result = {\n",
    "        'Model': model_name,\n",
    "        'Best_Params': best_params,\n",
    "        'Test_Accuracy': accuracy\n",
    "    }\n",
    "    results.append(result)\n",
    "    print(f'Finalizado el analisis de {model_name}\\n')\n",
    "    print(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado el analisis de XGBoost\n",
      "\n",
      "{'Model': 'XGBoost', 'Best_Params': {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 5, 'n_estimators': 30}, 'Test_Accuracy': 0.8771469465648855}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Params</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'booster': 'gbtree', 'eta': 0.1, 'max_depth':...</td>\n",
       "      <td>0.877147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model                                        Best_Params  Test_Accuracy\n",
       "0  XGBoost  {'booster': 'gbtree', 'eta': 0.1, 'max_depth':...       0.877147"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    #'LightGBM': LGBMClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    #'RandomForest': RandomForestClassifier(),\n",
    "    #'GradientBoosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    #'LightGBM':{'n_estimators': [10,30,50, 100, 200],'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "    'XGBoost': {'n_estimators': [ 30,50,70], 'max_depth': [5, 7,10],'booster':['gbtree'],'eta':[0.1,0.05]},\n",
    "    #'RandomForest': {'n_estimators': [50], 'max_depth': [None, 10]},\n",
    "    #'GradientBoosting': {'n_estimators': [50], 'max_depth': [3, 7]}\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train3, y_train3)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    y_pred = grid_search.predict(X_test3)\n",
    "    accuracy = accuracy_score(y_test3, y_pred)\n",
    "\n",
    "    result = {\n",
    "        'Model': model_name,\n",
    "        'Best_Params': best_params,\n",
    "        'Test_Accuracy': accuracy\n",
    "    }\n",
    "    results.append(result)\n",
    "    print(f'Finalizado el analisis de {model_name}\\n')\n",
    "    print(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01581876, 0.32862413, 0.01531592, 0.08909079, 0.39056945,\n",
       "       0.0220091 , 0.01381678, 0.07562838, 0.        , 0.04912677,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtener la importancia de las características\n",
    "feature_importance = grid_search.best_estimator_.feature_importances_\n",
    "\n",
    "# Crear un DataFrame para visualizar la importancia de las características\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X2.columns,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Visualizar la importancia de las características\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance in XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2 = pd.DataFrame(y_test2)\n",
    "\n",
    "y_test2['pred_result'] = y_pred2\n",
    "\n",
    "y_test2['Ok'] = (y_test2['Exited'] == y_test2['pred_result'])\n",
    "y_test2_final = pd.merge(y_test2,X_test2,left_index=True,right_index=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Ok', ylabel='count'>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_test2_final,x='Ok',hue='Exited')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exited</th>\n",
       "      <th>pred_result</th>\n",
       "      <th>Ok</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>678</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120853.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>569</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>119996.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>681</td>\n",
       "      <td>58.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>118749.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>633</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82298.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>682</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>96542.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164857</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>678</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18094.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164880</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>611</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>165020.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164882</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>728</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>174775.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164913</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>642</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>582.53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164988</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>655</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36548.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3930 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Exited  pred_result     Ok  CreditScore   Age  Tenure  Balance  \\\n",
       "69           1            1   True          678  43.0       8        1   \n",
       "108          1            1   True          569  43.0       3        0   \n",
       "110          1            1   True          681  58.0       9        1   \n",
       "128          1            1   True          633  52.0       3        1   \n",
       "129          0            0   True          682  34.0       5        1   \n",
       "...        ...          ...    ...          ...   ...     ...      ...   \n",
       "164857       0            0   True          678  51.0       1        0   \n",
       "164880       0            0   True          611  41.0       3        0   \n",
       "164882       1            0  False          728  33.0       8        1   \n",
       "164913       0            0   True          642  30.0       5        1   \n",
       "164988       1            0  False          655  39.0       5        0   \n",
       "\n",
       "        NumOfProducts  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
       "69                  1        120853.51                 0                  1   \n",
       "108                 1        119996.68                 1                  0   \n",
       "110                 2        118749.58                 0                  1   \n",
       "128                 1         82298.81                 0                  1   \n",
       "129                 1         96542.00                 0                  0   \n",
       "...               ...              ...               ...                ...   \n",
       "164857              2         18094.96                 1                  0   \n",
       "164880              2        165020.63                 1                  0   \n",
       "164882              1        174775.20                 0                  0   \n",
       "164913              1           582.53                 0                  1   \n",
       "164988              1         36548.00                 1                  0   \n",
       "\n",
       "        Geography_Spain  Gender_Female  Gender_Male  \n",
       "69                    0              1            0  \n",
       "108                   0              0            1  \n",
       "110                   0              0            1  \n",
       "128                   0              1            0  \n",
       "129                   1              0            1  \n",
       "...                 ...            ...          ...  \n",
       "164857                0              1            0  \n",
       "164880                0              0            1  \n",
       "164882                1              0            1  \n",
       "164913                0              1            0  \n",
       "164988                0              0            1  \n",
       "\n",
       "[3930 rows x 14 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test2_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['Exited'])\n",
    "y = df_train.Exited\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado el analisis de XGBoost\n",
      "\n",
      "{'Model': 'XGBoost', 'Best_Params': {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 5, 'n_estimators': 70}, 'Test_Accuracy': 0.8653012997243009}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Params</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'booster': 'gbtree', 'eta': 0.1, 'max_depth':...</td>\n",
       "      <td>0.865301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model                                        Best_Params  Test_Accuracy\n",
       "0  XGBoost  {'booster': 'gbtree', 'eta': 0.1, 'max_depth':...       0.865301"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    #'LightGBM': LGBMClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    #'RandomForest': RandomForestClassifier(),\n",
    "    #'GradientBoosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    #'LightGBM':{'n_estimators': [10,30,50, 100, 200],'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "    'XGBoost': {'n_estimators': [ 30,50,70], 'max_depth': [5, 7,10],'booster':['gbtree'],'eta':[0.1,0.05]},\n",
    "    #'RandomForest': {'n_estimators': [50], 'max_depth': [None, 10]},\n",
    "    #'GradientBoosting': {'n_estimators': [50], 'max_depth': [3, 7]}\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    result = {\n",
    "        'Model': model_name,\n",
    "        'Best_Params': best_params,\n",
    "        'Test_Accuracy': accuracy\n",
    "    }\n",
    "    results.append(result)\n",
    "    print(f'Finalizado el analisis de {model_name}\\n')\n",
    "    print(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "y_test_df['pred_result'] = y_pred\n",
    "\n",
    "y_test_df['Ok'] = (y_test_df['Exited'] == y_test_df['pred_result'])\n",
    "y_test_df = pd.merge(y_test_df,X_test,left_index=True,right_index=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exited</th>\n",
       "      <th>pred_result</th>\n",
       "      <th>Ok</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>678</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>773</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87549.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>703</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131363.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>785</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170968.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>752</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1187.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>679</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144880.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>659</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100929.59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165017</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>598</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187840.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165024</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>592</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176747.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165028</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>630</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5962.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33007 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Exited  pred_result     Ok  CreditScore   Age  Tenure  Balance  \\\n",
       "2            0            0   True          678  40.0      10        0   \n",
       "20           0            0   True          773  35.0       9        0   \n",
       "25           1            0  False          703  39.0       9        0   \n",
       "28           1            0  False          785  41.0       4        0   \n",
       "37           0            0   True          752  37.0       6        0   \n",
       "...        ...          ...    ...          ...   ...     ...      ...   \n",
       "165008       0            0   True          679  47.0       5        1   \n",
       "165013       0            0   True          659  39.0       2        0   \n",
       "165017       0            0   True          598  40.0       2        0   \n",
       "165024       1            0  False          592  33.0       3        1   \n",
       "165028       0            0   True          630  50.0       8        0   \n",
       "\n",
       "        NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "2                   2        1.0             0.0        184866.69   \n",
       "20                  2        0.0             1.0         87549.36   \n",
       "25                  1        1.0             0.0        131363.57   \n",
       "28                  1        1.0             0.0        170968.99   \n",
       "37                  2        0.0             0.0          1187.88   \n",
       "...               ...        ...             ...              ...   \n",
       "165008              1        1.0             1.0        144880.81   \n",
       "165013              2        1.0             1.0        100929.59   \n",
       "165017              2        1.0             0.0        187840.51   \n",
       "165024              2        1.0             1.0        176747.66   \n",
       "165028              2        1.0             1.0          5962.50   \n",
       "\n",
       "        Geography_France  Geography_Germany  Geography_Spain  Gender_Female  \\\n",
       "2                      1                  0                0              0   \n",
       "20                     0                  0                1              0   \n",
       "25                     0                  0                1              0   \n",
       "28                     0                  0                1              0   \n",
       "37                     1                  0                0              0   \n",
       "...                  ...                ...              ...            ...   \n",
       "165008                 0                  0                1              1   \n",
       "165013                 1                  0                0              1   \n",
       "165017                 1                  0                0              0   \n",
       "165024                 0                  1                0              1   \n",
       "165028                 1                  0                0              0   \n",
       "\n",
       "        Gender_Male  \n",
       "2                 1  \n",
       "20                1  \n",
       "25                1  \n",
       "28                1  \n",
       "37                1  \n",
       "...             ...  \n",
       "165008            0  \n",
       "165013            0  \n",
       "165017            1  \n",
       "165024            0  \n",
       "165028            1  \n",
       "\n",
       "[33007 rows x 16 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8124054462934948\n"
     ]
    }
   ],
   "source": [
    "y_pred_cond = y_test_df[(y_test_df.IsActiveMember == 0) & (y_test_df.HasCrCard == 0)].pred_result\n",
    "y_test_cond = y_test_df[(y_test_df.IsActiveMember == 0) & (y_test_df.HasCrCard == 0)].Exited\n",
    "\n",
    "print(accuracy_score(y_test_cond,y_pred_cond))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3966,)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exited</th>\n",
       "      <th>pred_result</th>\n",
       "      <th>Ok</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>678</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>773</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87549.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>703</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131363.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>785</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170968.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>752</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1187.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>679</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144880.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>659</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100929.59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165017</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>598</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187840.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165024</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>592</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176747.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165028</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>630</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5962.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33007 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Exited  pred_result     Ok  CreditScore   Age  Tenure  Balance  \\\n",
       "2            0            0   True          678  40.0      10        0   \n",
       "20           0            0   True          773  35.0       9        0   \n",
       "25           1            0  False          703  39.0       9        0   \n",
       "28           1            0  False          785  41.0       4        0   \n",
       "37           0            0   True          752  37.0       6        0   \n",
       "...        ...          ...    ...          ...   ...     ...      ...   \n",
       "165008       0            0   True          679  47.0       5        1   \n",
       "165013       0            0   True          659  39.0       2        0   \n",
       "165017       0            0   True          598  40.0       2        0   \n",
       "165024       1            0  False          592  33.0       3        1   \n",
       "165028       0            0   True          630  50.0       8        0   \n",
       "\n",
       "        NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "2                   2        1.0             0.0        184866.69   \n",
       "20                  2        0.0             1.0         87549.36   \n",
       "25                  1        1.0             0.0        131363.57   \n",
       "28                  1        1.0             0.0        170968.99   \n",
       "37                  2        0.0             0.0          1187.88   \n",
       "...               ...        ...             ...              ...   \n",
       "165008              1        1.0             1.0        144880.81   \n",
       "165013              2        1.0             1.0        100929.59   \n",
       "165017              2        1.0             0.0        187840.51   \n",
       "165024              2        1.0             1.0        176747.66   \n",
       "165028              2        1.0             1.0          5962.50   \n",
       "\n",
       "        Geography_France  Geography_Germany  Geography_Spain  Gender_Female  \\\n",
       "2                      1                  0                0              0   \n",
       "20                     0                  0                1              0   \n",
       "25                     0                  0                1              0   \n",
       "28                     0                  0                1              0   \n",
       "37                     1                  0                0              0   \n",
       "...                  ...                ...              ...            ...   \n",
       "165008                 0                  0                1              1   \n",
       "165013                 1                  0                0              1   \n",
       "165017                 1                  0                0              0   \n",
       "165024                 0                  1                0              1   \n",
       "165028                 1                  0                0              0   \n",
       "\n",
       "        Gender_Male  \n",
       "2                 1  \n",
       "20                1  \n",
       "25                1  \n",
       "28                1  \n",
       "37                1  \n",
       "...             ...  \n",
       "165008            0  \n",
       "165013            0  \n",
       "165017            1  \n",
       "165024            0  \n",
       "165028            1  \n",
       "\n",
       "[33007 rows x 16 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[(df_train.IsActiveMember == 0) & (df_train.HasCrCard == 0)].drop(columns=['Exited'])\n",
    "y = df_train[(df_train.IsActiveMember == 0) & (df_train.HasCrCard == 0)].Exited\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19646, 13)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado el analisis de XGBoost\n",
      "\n",
      "{'Model': 'XGBoost', 'Best_Params': {'booster': 'gbtree', 'eta': 0.1, 'n_estimators': 50}, 'Test_Accuracy': 0.8106870229007633}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'Other': SVC()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'XGBoost': {'n_estimators': [10, 30, 50, 70, 100],'booster':['gbtree'],'eta':[0.3,0.1]},\n",
    "    'Other': {'C': [0.1,1,10],'kernel':['linear','sigmoid','poly','rbf'],'gamma': [0.1, 1, 'scale', 'auto']}\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    result = {\n",
    "        'Model': model_name,\n",
    "        'Best_Params': best_params,\n",
    "        'Test_Accuracy': accuracy\n",
    "    }\n",
    "    results.append(result)\n",
    "    print(f'Finalizado el analisis de {model_name}\\n')\n",
    "    print(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['Exited'])\n",
    "y = df_train.Exited\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22349, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211596 -> initscore=-1.315331\n",
      "[LightGBM] [Info] Start training from score -1.315331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 22350, number of negative: 83272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 105622, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211604 -> initscore=-1.315286\n",
      "[LightGBM] [Info] Start training from score -1.315286\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 27937, number of negative: 104090\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 132027, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211601 -> initscore=-1.315304\n",
      "[LightGBM] [Info] Start training from score -1.315304\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Finalizado el analisis de LightGBM\n",
      "\n",
      "{'Model': 'LightGBM', 'Best_Params': {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}, 'Test_Accuracy': 0.8875891366078972}\n",
      "Finalizado el analisis de XGBoost\n",
      "\n",
      "{'Model': 'XGBoost', 'Best_Params': {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 5, 'n_estimators': 70}, 'Test_Accuracy': 0.8875547697056604}\n",
      "Finalizado el analisis de RandomForest\n",
      "\n",
      "{'Model': 'RandomForest', 'Best_Params': {'max_depth': 10, 'n_estimators': 50}, 'Test_Accuracy': 0.8849995222967575}\n",
      "Finalizado el analisis de GradientBoosting\n",
      "\n",
      "{'Model': 'GradientBoosting', 'Best_Params': {'max_depth': 7, 'n_estimators': 50}, 'Test_Accuracy': 0.8871570633238839}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Params</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.887589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'booster': 'gbtree', 'eta': 0.1, 'max_depth':...</td>\n",
       "      <td>0.887555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 50}</td>\n",
       "      <td>0.887157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model                                        Best_Params  \\\n",
       "0          LightGBM  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...   \n",
       "1           XGBoost  {'booster': 'gbtree', 'eta': 0.1, 'max_depth':...   \n",
       "2      RandomForest              {'max_depth': 10, 'n_estimators': 50}   \n",
       "3  GradientBoosting               {'max_depth': 7, 'n_estimators': 50}   \n",
       "\n",
       "   Test_Accuracy  \n",
       "0       0.887589  \n",
       "1       0.887555  \n",
       "2       0.885000  \n",
       "3       0.887157  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "models = {\n",
    "    'LightGBM': LGBMClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'LightGBM':{'n_estimators': [10,30,50, 100, 200],'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]},\n",
    "    'XGBoost': {'n_estimators': [ 30,50,70], 'max_depth': [5, 7,10],'booster':['gbtree'],'eta':[0.1,0.05]},\n",
    "    'RandomForest': {'n_estimators': [50], 'max_depth': [None, 10]},\n",
    "    'GradientBoosting': {'n_estimators': [50], 'max_depth': [3, 7]}\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    y_probs = grid_search.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Compute ROC curve and AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "    result = {\n",
    "        'Model': model_name,\n",
    "        'Best_Params': best_params,\n",
    "        'Test_Accuracy': roc_auc\n",
    "    }\n",
    "    results.append(result)\n",
    "    print(f'Finalizado el analisis de {model_name}\\n')\n",
    "    print(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
